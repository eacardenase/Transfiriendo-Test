{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwqcWZ447h-1"
   },
   "source": [
    "Descripción \n",
    "# Conjunto de datos públicos brasileños de comercio electrónico de Olist\n",
    "***\n",
    "¡Bienvenido! Este es un conjunto de datos públicos de comercio electrónico brasileño de pedidos realizados en Olist Store. El conjunto de datos tiene información de 100k pedidos de 2016 a 2018 realizados en múltiples mercados en Brasil. Sus características permiten ver un pedido desde múltiples dimensiones: desde el estado del pedido, el precio, el pago y el desempeño del flete hasta la ubicación del cliente, los atributos del producto y finalmente las reseñas escritas por los clientes. También publicamos un conjunto de datos de geolocalización que relaciona los códigos postales brasileños con las coordenadas lat / lng.\n",
    "\n",
    "Estos son datos comerciales reales, se han anonimizado y las referencias a las empresas y socios en el texto de revisión se han reemplazado con los nombres de las grandes casas de Game of Thrones.\n",
    "\n",
    "# Join it With the Marketing Funnel by Olist\n",
    "También hemos lanzado un conjunto de datos de embudo de marketing https://www.kaggle.com/olistbr/marketing-funnel-olist/home ¡Puede unir ambos conjuntos de datos y ver un pedido desde la perspectiva de marketing ahora!\n",
    "\n",
    "Las instrucciones para unirse están disponibles en este Kernel https://www.kaggle.com/andresionek/joining-marketing-funnel-with-brazilian-e-commerce.\n",
    "\n",
    "# Contexto\n",
    "Este conjunto de datos fue proporcionado generosamente por Olist, la tienda por departamentos más grande de los mercados brasileños. Olist conecta pequeñas empresas de todo Brasil con canales sin problemas y con un solo contrato. Esos comerciantes pueden vender sus productos a través de Olist Store y enviarlos directamente a los clientes mediante los socios logísticos de Olist. Vea más en nuestro sitio web: www.olist.com\n",
    "\n",
    "Después de que un cliente compra el producto en Olist Store, un vendedor recibe una notificación para cumplir con ese pedido. Una vez que el cliente recibe el producto, o vence la fecha estimada de entrega, el cliente recibe una encuesta de satisfacción por correo electrónico donde puede dar una nota por la experiencia de compra y anotar algunos comentarios.\n",
    "\n",
    "# Atención\n",
    "1. Un pedido puede tener varios artículos.\n",
    "2. Cada artículo puede ser realizado por un vendedor distinto.\n",
    "3. Todo el texto que identifica tiendas y socios fue reemplazado por los nombres de las grandes casas de Game of Thrones.\n",
    "\n",
    "\n",
    "# Ejemplo de una lista de productos en un mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtxvCNnc7uFd"
   },
   "source": [
    "![image](https://i.imgur.com/JuJMns1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UXT38eO9zr0"
   },
   "source": [
    "# Data Schema\n",
    "Los datos se dividen en varios conjuntos de datos para una mejor comprensión y organización. Consulte el siguiente esquema de datos cuando trabaje con él:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOVjjxBu99dr"
   },
   "source": [
    "![image](https://i.imgur.com/HRhd2Y0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHC4_Apq_lT3"
   },
   "source": [
    "# Classified Dataset\n",
    "Anteriormente habíamos publicado un conjunto de datos clasificados, pero lo eliminamos en la Versión 6. Tenemos la intención de publicarlo nuevamente como un nuevo conjunto de datos con un nuevo esquema de datos. Si bien no lo terminamos, puede usar el conjunto de datos clasificados disponible en la Versión 5 o anterior.\n",
    "\n",
    "# Inspiration\n",
    "Aquí hay algo de inspiración para los posibles resultados de este conjunto de datos.\n",
    "\n",
    "# NLP:\n",
    "\n",
    "Este conjunto de datos ofrece un entorno supremo para analizar el texto de las reseñas a través de sus múltiples dimensiones.\n",
    "\n",
    "# Clustering:\n",
    "\n",
    "Algunos clientes no escribieron una reseña. Pero, ¿por qué están felices o enojados?\n",
    "\n",
    "# Sales Prediction:\n",
    "\n",
    "Con la información de la fecha de compra, podrá predecir las ventas futuras.\n",
    "\n",
    "# Delivery Performance:\n",
    "\n",
    "También podrá trabajar en el desempeño de la entrega y encontrar formas de optimizar los tiempos de entrega.\n",
    "\n",
    "# Product Quality:\n",
    "\n",
    "Disfrute descubriendo las categorías de productos que son más propensas a la insatisfacción del cliente.\n",
    "\n",
    "# Feature Engineering:\n",
    "\n",
    "Cree características a partir de este rico conjunto de datos o adjúntele información pública externa.\n",
    "\n",
    "# Acknowledgements\n",
    "\n",
    "Gracias a Olist por publicar este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVojHYiQqOKf"
   },
   "source": [
    "# Tareas\n",
    "\n",
    "Realizar\n",
    "* Código mantenible y código limpio\n",
    "* Analisis Exploratorio de Datos\n",
    "* Interpretación del problema\n",
    "* Ingeniería de características\n",
    "* Series temporales\n",
    "* Modelos\n",
    "* Predicción de ventas\n",
    "* Optimización entregas pedidos\n",
    "* Clasificación\n",
    "* Procesamiento de lenguaje Natural\n",
    "* Dedicación\n",
    "* Exposición\n",
    "* Presentación y claridad\n",
    "\n",
    "# Entregables\n",
    "\n",
    "Elegir la herramienta con la que se sientan mejor\n",
    "\n",
    "* Word\n",
    "* Power Point\n",
    "* Excel\n",
    "* Kaggle\n",
    "* Colab\n",
    "* Streamlit, bokeh, dash, heroku\n",
    "* Spyder\n",
    "* Jupyter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X7CLfUHqFrn"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteamiento del problema\n",
    "\n",
    "## 1. AS\n",
    "\n",
    "### Asdas\n",
    "\n",
    "asdansjnfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Bases de Datos proporcionadas por Olist ###\")\n",
    "print(\"\\n\",('-'*45),\"\\n\")\n",
    "for indice, archivo in enumerate(os.listdir(\"/home/eacardenase/Documents/Trabajo/\\\n",
    "Transfiriendo-Test/Data\")):\n",
    "    print(indice + 1, \"-\", archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(\"olist_customers_dataset.csv\")\n",
    "geolocation = pd.read_csv(\"olist_geolocation_dataset.csv\")\n",
    "order_items = pd.read_csv(\"olist_order_items_dataset.csv\")\n",
    "order_payments = pd.read_csv(\"olist_order_payments_dataset.csv\")\n",
    "order_reviews = pd.read_csv(\"olist_order_reviews_dataset.csv\")\n",
    "orders = pd.read_csv(\"olist_orders_dataset.csv\")\n",
    "products = pd.read_csv(\"olist_products_dataset.csv\")\n",
    "sellers = pd.read_csv(\"olist_sellers_dataset.csv\")\n",
    "product_translation = pd.read_csv(\"product_category_name_translation.csv\")\n",
    "closed_deals = pd.read_csv(\"olist_closed_deals_dataset.csv\")\n",
    "mql = pd.read_csv(\"olist_marketing_qualified_leads_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_ptg = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos una copia del dataset original para efectuar los analisis y conservar la informacion\n",
    "reviews = order_reviews.copy()\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas de la columna review en donde se presenten NaN\n",
    "reviews = reviews.dropna(subset=[\"review_comment_message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Contamos con un total de {len(reviews)} datos sobre las reviews de los \\\n",
    "clientes para realizar NLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = round(sum(reviews.duplicated(\"review_id\"))/len(reviews)*100, 2)\n",
    "print(f\" Hay {duplicados}% de reviews duplicados basados en los id.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminacion de duplicados basado en los id\n",
    "reviews = reviews.drop_duplicates(\"review_id\")\n",
    "reviews = reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews_cleaned = reviews[\"review_comment_message\"]\n",
    "reviews_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos cada fila de la columna reviews_message en una lista para facilitar limpieza\n",
    "texto = []\n",
    "\n",
    "for fila in reviews_cleaned:\n",
    "    texto.append(fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos cada palabra en cada una de las listas en minuscula para facilitar analisis\n",
    "texto = [palabra.lower() for palabra in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos numeros y caracteres especiales\n",
    "texto_limpio = []\n",
    "\n",
    "for palabra in texto:\n",
    "    palabra = re.sub(r\"[\\W\\d]\", \" \", palabra)\n",
    "    texto_limpio.append(palabra.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texto_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = []\n",
    "\n",
    "for palabra in texto_limpio:\n",
    "    palabra = palabra.split()\n",
    "    texto.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion para convertir una lista en un string\n",
    "def listToString(lista):\n",
    "    string = \" \"\n",
    "    return string.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos las palabras vacias cada lista dentro de texto, y luego\n",
    "# convertimos nuevamente esa lista en un string\n",
    "\n",
    "pre_procesado = []\n",
    "for lista in texto:\n",
    "    lista = [word for word in lista if word not in stopwords_ptg]\n",
    "    lista = listToString(lista)    \n",
    "    pre_procesado.append(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_procesado[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_pre = pd.DataFrame({\"reviews_pre\": pre_procesado})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"review_procesed\"] = reviews_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_totales = reviews[\"review_procesed\"]\n",
    "\n",
    "words = []\n",
    "\n",
    "for word in palabras_totales:\n",
    "    lista = word.split()\n",
    "    for palabra in lista:\n",
    "        words.append(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_de_palabras = pd.Series(words)\n",
    "frecuencia_de_palabras.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConteoDePalabras(lista):\n",
    "    wordfreq = {'palabra':[],'frecuencia':[]}\n",
    "    for palanra in lista:\n",
    "        if palabra not in wordfreq['frecuencia']:\n",
    "            wordfreq['palabra'].append(palabra)                   # save word\n",
    "            wordfreq['frecuencia'].append(lista.count(palabra))   # save freq\n",
    "    conteo = pd.DataFrame(wordfreq)\n",
    "    conteo_ordenado = conteo.sort_values(\"palabra\", ascending=False)\n",
    "    return conteo_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_finales = ConteoDePalabras(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf = mql.merge(closed_deals, on = \"mql_id\", how = \"left\")\n",
    "# mf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf_sellers = mf.merge(sellers, on = \"seller_id\", how = \"left\")\n",
    "# mf_sellers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf_items = mf.merge(order_items, on = \"seller_id\", how = \"left\")\n",
    "# mf_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Olist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
